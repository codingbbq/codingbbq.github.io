"use strict";(self.webpackChunkcodingbbq_github_io=self.webpackChunkcodingbbq_github_io||[]).push([[8480],{8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var i=t(6540);const s={},r=i.createContext(s);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(r.Provider,{value:n},e.children)}},8677:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"AI/RAG","title":"What is RAG in AI?","description":"When an AI answers a question, it needs two things:","source":"@site/docs/AI/RAG.md","sourceDirName":"AI","slug":"/AI/RAG","permalink":"/docs/AI/RAG","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"sidebar_label":"RAG"},"sidebar":"tutorialSidebar","previous":{"title":"Prompt Engineering","permalink":"/docs/AI/prompt-engineering"},"next":{"title":"Agents","permalink":"/docs/AI/Agents"}}');var s=t(4848),r=t(8453);const o={sidebar_position:5,sidebar_label:"RAG"},a="What is RAG in AI?",c={},d=[];function l(e){const n={h1:"h1",header:"header",li:"li",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"what-is-rag-in-ai",children:"What is RAG in AI?"})}),"\n",(0,s.jsx)("div",{className:"text--center",children:(0,s.jsx)("img",{src:"/img/RAG.png",alt:"RAG overview",width:"600"})}),"\n",(0,s.jsx)(n.p,{children:"When an AI answers a question, it needs two things:\r\n1\ufe0f\u20e3 Instructions on how to answer\r\n2\ufe0f\u20e3 Information on what to answer"}),"\n",(0,s.jsx)(n.p,{children:"If either is missing, the answer can be wrong\u2014just like a human guessing without enough context."}),"\n",(0,s.jsx)(n.p,{children:"This is where RAG (Retrieval-Augmented Generation) comes in.\r\nInstead of asking the AI to answer everything from memory, RAG lets it:"}),"\n",(0,s.jsx)(n.p,{children:"\u2714\ufe0f first look up the right information"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"a company database"}),"\n",(0,s.jsx)(n.li,{children:"user-specific data"}),"\n",(0,s.jsx)(n.li,{children:"previous conversations"}),"\n",(0,s.jsx)(n.li,{children:"documents or the internet"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"\u2714\ufe0f then use that information to generate an answer"}),"\n",(0,s.jsx)(n.p,{children:"\ud83d\udd0d Why RAG matters"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"It reduces hallucinations"}),"\n",(0,s.jsx)(n.li,{children:"It gives more accurate, up-to-date answers"}),"\n",(0,s.jsx)(n.li,{children:"It allows context to be specific to each question, not shared across all users"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"\u2049\ufe0f Can we just put the context in the prompt? Why do we need RAG?\r\nYes, you can put context directly in the prompt \u2014 but it doesn\u2019t scale."}),"\n",(0,s.jsx)(n.p,{children:"\ud83d\udd35 Context size limits\r\nLLMs have a fixed context window, so pasting large documents or datasets directly into prompts quickly becomes impractical. RAG retrieves only the most relevant information needed for each query."}),"\n",(0,s.jsx)(n.p,{children:"\ud83d\udd35 Scalability\r\nEmbedding context in prompts may work for small demos, but it doesn\u2019t scale when each user and question requires different data. RAG dynamically builds context per request instead of relying on static prompts."}),"\n",(0,s.jsx)(n.p,{children:"\ud83d\udd35 Accuracy and hallucination reduction\r\nWhen models lack the right information, they tend to guess. RAG supplies verified, relevant data at query time, significantly reducing hallucinations."}),"\n",(0,s.jsx)(n.p,{children:"\ud83d\udd35 Security and data isolation\r\nPutting all data in prompts risks mixing or exposing sensitive information. RAG ensures only user-specific and query-relevant data is retrieved and shared with the model."}),"\n",(0,s.jsx)(n.p,{children:"\ud83d\udd35 Maintainability and freshness\r\nUpdating prompt-embedded knowledge is difficult and error-prone. With RAG, you simply update the data source\u2014no prompt rewrites or model retraining required."}),"\n",(0,s.jsx)(n.p,{children:"RAG is such a powerful pattern for real-world AI applications."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}}}]);