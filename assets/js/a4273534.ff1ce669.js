"use strict";(self.webpackChunkcodingbbq_github_io=self.webpackChunkcodingbbq_github_io||[]).push([[5976],{6385:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"AI/Parameters","title":"Parameters","description":"When people say an AI model is \u201clarge\u201d, they\u2019re usually talking about parameters.","source":"@site/docs/AI/Parameters.md","sourceDirName":"AI","slug":"/AI/Parameters","permalink":"/docs/AI/Parameters","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"sidebar_label":"Parameters"},"sidebar":"tutorialSidebar","previous":{"title":"Tokens","permalink":"/docs/AI/Tokens"},"next":{"title":"Foundation Models","permalink":"/docs/AI/Foundation-Models"}}');var t=r(4848),i=r(8453);const a={sidebar_position:2,sidebar_label:"Parameters"},o=void 0,l={},d=[];function c(e){const n={li:"li",p:"p",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)("div",{className:"text--center",children:(0,t.jsx)("img",{src:"/img/parameters-in-llm.png",alt:"Parameters overview",width:"600"})}),"\n",(0,t.jsx)(n.p,{children:"When people say an AI model is \u201clarge\u201d, they\u2019re usually talking about parameters."}),"\n",(0,t.jsx)(n.p,{children:"So what are parameters?"}),"\n",(0,t.jsx)(n.p,{children:"At the simplest level, parameters are numbers the model learns during training."}),"\n",(0,t.jsx)(n.p,{children:"These numbers decide:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"how words relate to each other"}),"\n",(0,t.jsx)(n.li,{children:"how strong those relationships are"}),"\n",(0,t.jsx)(n.li,{children:"what the most likely next word should be"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"When you type:\r\n\ud83d\udc49 \u201cI love drinking hot ___\u201d"}),"\n",(0,t.jsx)(n.p,{children:"The model doesn\u2019t guess randomly.\r\nIt uses millions or billions of learned numbers (parameters) to score options like tea, coffee, or soup \u2014 and picks the most likely one."}),"\n",(0,t.jsx)(n.p,{children:"Inside an LLM:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Words are converted into numbers (embeddings)"}),"\n",(0,t.jsx)(n.li,{children:"Those numbers flow through layers of matrices"}),"\n",(0,t.jsx)(n.li,{children:"Each matrix contains weights (these are parameters)"}),"\n",(0,t.jsx)(n.li,{children:"During training, these weights are adjusted to reduce prediction errors"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"\ud83d\udcc8 Why more parameters matter"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Better context understanding"}),"\n",(0,t.jsx)(n.li,{children:"Ability to model subtle language patterns"}),"\n",(0,t.jsx)(n.li,{children:"Improved reasoning and fluency"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"\u26a0\ufe0f But more parameters also mean:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Higher compute cost"}),"\n",(0,t.jsx)(n.li,{children:"More memory usage"}),"\n",(0,t.jsx)(n.li,{children:"More careful training and evaluation"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:'So when you hear:\r\n\u201cThis model has billions of parameters\u201d\r\nIt really means:\r\n"The model has learned billions of numerical relationships about language."'}),"\n",(0,t.jsx)(n.p,{children:"That\u2019s what makes LLMs powerful."})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>o});var s=r(6540);const t={},i=s.createContext(t);function a(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);